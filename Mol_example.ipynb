{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"datasets/dgsm/chembl_22_clean_1576904_sorted_std_final.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mol2vec.mol2vec_encoder import Mol2VecEncoder\n",
    "\n",
    "m2v_encoder = Mol2VecEncoder(\"models/mol2vec/model_300dim.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_sample = df[\"SMILES\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2v_encoder.smiles_to_vec(smiles_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_parquet_with_mol2vec(parquet_path, model_path, output_dir, batch_size=1000):\n",
    "    \"\"\"\n",
    "    Process parquet file with mol2vec and save embeddings\n",
    "    \n",
    "    Args:\n",
    "        parquet_path (str): Path to parquet file\n",
    "        model_path (str): Path to mol2vec model\n",
    "        output_dir (str): Directory to save embeddings\n",
    "        batch_size (int): Number of rows to process at once\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize encoder\n",
    "        print(\"Initializing Mol2Vec encoder...\")\n",
    "        encoder = Mol2VecEncoder(model_path)\n",
    "        \n",
    "        # Read parquet file\n",
    "        print(\"Reading parquet file...\")\n",
    "        df = pd.read_parquet(parquet_path)\n",
    "        total_rows = len(df)\n",
    "        print(f\"Total rows to process: {total_rows}\")\n",
    "        \n",
    "        # Process in batches with tqdm\n",
    "        failed_indices = []\n",
    "        successful_embeddings = 0\n",
    "        \n",
    "        for start_idx in tqdm(range(0, total_rows, batch_size), \n",
    "                            desc=\"Processing molecules\", \n",
    "                            unit=\"batch\"):\n",
    "            end_idx = min(start_idx + batch_size, total_rows)\n",
    "            batch = df.iloc[start_idx:end_idx]\n",
    "            \n",
    "            # Process each SMILES in the batch\n",
    "            for idx, row in batch.iterrows():\n",
    "                try:\n",
    "                    # Get embedding\n",
    "                    embedding = encoder.smiles_to_vec(row['SMILES'])\n",
    "                    \n",
    "                    if embedding is not None:\n",
    "                        # Save embedding to file\n",
    "                        output_path = os.path.join(output_dir, f\"{idx}.npy\")\n",
    "                        np.save(output_path, embedding)\n",
    "                        successful_embeddings += 1\n",
    "                    else:\n",
    "                        failed_indices.append(idx)\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing index {idx}: {str(e)}\")\n",
    "                    failed_indices.append(idx)\n",
    "                    \n",
    "        # Print summary\n",
    "        print(\"\\nProcessing complete!\")\n",
    "        print(f\"Successfully processed: {successful_embeddings}/{total_rows} molecules\")\n",
    "        print(f\"Failed to process: {len(failed_indices)} molecules\")\n",
    "        \n",
    "        if failed_indices:\n",
    "            failed_file = os.path.join(output_dir, \"failed_indices.txt\")\n",
    "            with open(failed_file, 'w') as f:\n",
    "                f.write(\"\\n\".join(map(str, failed_indices)))\n",
    "            print(f\"Failed indices saved to: {failed_file}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in main processing: {str(e)}\")\n",
    "\n",
    "def verify_embeddings(output_dir):\n",
    "    \"\"\"\n",
    "    Verify the saved embeddings\n",
    "    \n",
    "    Args:\n",
    "        output_dir (str): Directory containing embeddings\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get all npy files\n",
    "        embedding_files = [f for f in os.listdir(output_dir) if f.endswith('.npy')]\n",
    "        print(f\"\\nVerifying {len(embedding_files)} embedding files...\")\n",
    "        \n",
    "        # Check a few random files\n",
    "        sample_size = min(5, len(embedding_files))\n",
    "        sample_files = np.random.choice(embedding_files, sample_size, replace=False)\n",
    "        \n",
    "        for file in sample_files:\n",
    "            file_path = os.path.join(output_dir, file)\n",
    "            embedding = np.load(file_path)\n",
    "            print(f\"File: {file}, Shape: {embedding.shape}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error verifying embeddings: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_FILE = 'datasets/dgsm/chembl_22_clean_1576904_sorted_std_final.parquet'\n",
    "MODEL_PATH = 'models/mol2vec/model_300dim.pkl'  # Update with your model path\n",
    "OUTPUT_DIR = 'storages/mol2vec_dgsm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_parquet_with_mol2vec(PARQUET_FILE, MODEL_PATH, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eigenmol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
